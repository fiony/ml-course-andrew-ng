# Andrew Ng's Machine Learning Course Excercise

Python implementation of programming exercises from [Machine Learning](https://www.coursera.org/learn/machine-learning/home/info) course taught by [Andrew Ng](https://www.coursera.org/instructor/andrewng) on coursea.

The code is implementated in Python 3, and output is illustrated by [Jupyter](http://jupyter.org/) notebook. 


## Exercise 1: Linear Regression 
[source](https://github.com/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb) | [notebook](https://nbviewer.jupyter.org/github/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb)
- [Warmup Excercise](https://nbviewer.jupyter.org/github/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb#Warmup-Excercise-:-Return-the-5x5-identity-matrix)
- [Linear regression with one variable](https://nbviewer.jupyter.org/github/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb#Linear-regression-with-one-variable)
  - [Gradient Descent](https://nbviewer.jupyter.org/github/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb#Gradient-Descent)
  - [Visualizing Cost Function](https://nbviewer.jupyter.org/github/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb#Visualizing-Cost-Function-$J(\theta)$)
  - [Visualize Gradient Descent Algorithm](https://nbviewer.jupyter.org/github/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb#Visualize-Gradient-Descent-Algorithm)
  - [Running with Different Learning Rate](https://nbviewer.jupyter.org/github/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb#Run-with-different-Learning-Rate-$\alpha$)
- [Linear regression with multiple variables](https://nbviewer.jupyter.org/github/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb#Linear-regression-with-multiple-variables)
   - [Feature Normalization](https://nbviewer.jupyter.org/github/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb#Feature-Normalization)
   - [Gradient Descent](https://nbviewer.jupyter.org/github/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb#Gradient-Descent)   
   - [Visualize Training Examples](https://nbviewer.jupyter.org/github/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb#Visualize-Training-Examples)
   - [Select Learning Rate](https://nbviewer.jupyter.org/github/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb#Select-Learning-Rate)
   - [Run with selected learning rate](https://nbviewer.jupyter.org/github/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb#Run-with-selected-alpha)
- [Normal Equations](https://nbviewer.jupyter.org/github/fiony/ml-course-andrew-ng/blob/master/ex1/Programming%20Exercise%201-Linear%20Regression.ipynb#Normal-Equations)
   

  
